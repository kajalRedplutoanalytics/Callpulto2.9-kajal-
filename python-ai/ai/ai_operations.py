"""This module provides functionality to transcribe audio files to English using the Gemini API.
It includes functions to transcribe audio, extract stock data from transcriptions, and analyze conversations for missed business opportunities.
"""


import os
import json
from google import genai
from google.genai import types
from dotenv import load_dotenv
from utils.logger import get_logger
from google.api_core import retry, exceptions
from db.config import GEMINI_API_KEY, COMPLETE_FOLDER
from pydantic import BaseModel, Field, create_model
from typing import Optional, Literal, List
from datetime import datetime
from langchain_core.messages.utils import count_tokens_approximately
from ai.aiconfig import llm_module
from .prompts import transcribe_prompt, ConversationData, StockTransaction
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.output_parsers import PydanticOutputParser
from langchain.prompts import PromptTemplate
from dotenv import load_dotenv

load_dotenv()

logger = get_logger(__name__)

CLIENT = genai.Client(api_key=GEMINI_API_KEY)


def transcribe_audio(file_path):
    """
    Transcribes an audio file to English using the Gemini API. 
    The audio file should be in a supported format (e.g., MP3, WAV).
    Args:
        file_path (str): The path to the audio file to be transcribed.
    Returns:
        str: The transcription of the audio file in English, or None if an error occurs.
    """
    try:
        logger.info(f"AI_OPERATIONS.PY: Transcribing audio file path to English: {file_path}")
        
        # Upload the audio file and transcribe
        if llm_module=='gemini-2.0-flash':
            client = genai.Client(api_key=GEMINI_API_KEY)
        else:
            client = ''

        audio_file = client.files.upload(file=file_path)
        
        prompt = transcribe_prompt
        
        # Use the retry decorator to call the generate_content method
        result = client.models.generate_content(
            model='gemini-2.0-flash',
            contents=[prompt, audio_file],
            config=types.GenerateContentConfig(temperature=0.1)
        )
        
        estimated_tokens_for_1_apicall = result.usage_metadata.total_token_count
        words_count_apicall_1 = len(result.text.strip().split())

        logger.info(f"AI_OPERATIONS.PY: Total tokens used to transcribe the audio: ================ {estimated_tokens_for_1_apicall}")

        logger.info(f"AI_OPERATIONS.PY: total words generated by model on API call 1: {words_count_apicall_1}")

        logger.info("AI_OPERATIONS.PY: TRANSCRIPTION COMPLETED TO ENGLISH")
        
        # logger.info(f"AI_OPERATIONS.PY: Transcription: {result.text}")
        
        return result.text, estimated_tokens_for_1_apicall, words_count_apicall_1
    
    except Exception as e:
        logger.error(f"Error during transcription: {e}")
        return None





def get_stock_data( recording_name_without_ext: str, transcription: str, start_time: str, product_list: List[str],) -> ConversationData:
    """
    Extracts structured stock‐transaction + call‐level metrics
    from a conversation using Gemini via LangChain.
    """
    try:
        # 1) wrap your Pydantic schema in a LangChain parser
        parser = PydanticOutputParser(pydantic_object=ConversationData)

        # 2) build a single PromptTemplate that
        #    - tells the model your product-list & fallback time
        #    - injects the parser’s format instructions (i.e. the JSON schema)
        prompt = PromptTemplate(
                                template="""
                        You are an expert transcription analyst.
                        Extract all stock transactions and call-level metrics described by this schema.
                        – Valid stock names: {product_list}
                        – If a transaction has no time, use fallback start time: {start_time}

                        {format_instructions}

                        Transcription:
                        {transcription}
                        """,
                                input_variables=["transcription"],
                                partial_variables={
                                    "product_list": product_list,
                                    "start_time": start_time,
                                    "format_instructions": parser.get_format_instructions(),
                                },
                            )

        # 3) initialise the Gemini chat model
        chat = ChatGoogleGenerativeAI(
            model="gemini-2.0-flash",
            temperature=0.5,
            google_api_key=os.getenv("GEMINI_API_KEY"),
            convert_system_message_to_human=True,
        )
        # 4) Format the full prompt with transcription
        prompt_text = prompt.format(transcription=transcription)

        # 5) Get model output
        model_response = chat.invoke(prompt_text)

        # 6) Estimate token count
        estimated_tokens_for_2_apicall = model_response.usage_metadata['total_tokens']
        logger.info(f"AI_OPERATIONS.PY: Total tokens used to extract stock data: {estimated_tokens_for_2_apicall}")

        words_count_apicall_1 = len(model_response.content.strip().split())
        logger.info(f"AI_OPERATIONS.PY: Total words generated by model: {words_count_apicall_1}")

        # logger.info(f"AI_OPERATIONS.PY: Model response: {model_response.content}")
        # 7) Parse the output using the parser
        result: ConversationData = parser.invoke(model_response)
        
        logger.info(f"AI_OPERATIONS.PY: Extracted stock data: {result}")

        return result, estimated_tokens_for_2_apicall, words_count_apicall_1

    except Exception as e:
        logger.error(f"Error during stock data extraction: {e}")
        return None







# def get_stock_data(recording_name_without_ext, transcription, start_time, product_list):
    
#     try:
#         # product_list = get_all_product_names()
#         schema_json = json.dumps(ConversationData.model_json_schema(), indent=2)
        
#         logger.info("AI_OPERATIONS.PY: SCHEMA JSON CREATED")

#         # Dynamically inject product_list and validated start time
#         schema_json = schema_json.replace(
#             "Category of the product from the following list: []",
#             f"Category of the product from the following list: {product_list}"
#         ).replace(
#             "Provide order time in MM:SS format.",
#             f"Provide order time in MM:SS format. If missing, use this start time: {start_time}"
#         )

#         prompt = f"""
#         You are an expert transcription analyst. Extract transactions in this JSON format:

#         Schema:
#         {schema_json}

#         Transcription:
#         {transcription}

#         Return only valid JSON.
#         """

#         response = CLIENT.models.generate_content(
#             model="gemini-2.0-flash",
#             contents=[prompt],
#             config=types.GenerateContentConfig(temperature=0.1)
#         )
        
#         api2_token = response.usage_metadata.total_token_count
#         logger.info(f"AI_OPERATIONS.PY: Total tokens used extract Features from the transcription:============= {api2_token}")
#         logger.info("AI_OPERATIONS.PY: API CALL COMPLETED")

        
#         cleaned_text = re.sub(r"^```json\s*|```$", "", response.text.strip(), flags=re.DOTALL).strip()
#         stock_data = json.loads(cleaned_text)
#         stock_data["Recording_Name"] = recording_name_without_ext
#         stock_data["Transcription"] = transcription

        
#         logger.info("AI_OPERATIONS.PY: STOCK DATA EXTRACTION COMPLETED")
        
#         return stock_data, api2_token

#     except Exception as e:
#         logger.error(f"AI_OPERATIONS.PY: Error during stock data extraction: {e}")
#         return None

